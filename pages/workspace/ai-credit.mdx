# How AI Credits Work

MindPal uses a credit-based system for AI usage, where different AI models consume varying amounts of credits per request. This guide will help you understand what AI credits are and how to manage them effectively.

## What is an AI Credit?

An AI credit is MindPal's unit of AI usage measurement. The number of credits consumed depends on the specific AI model you choose. Models like Gemini 2.5 Flash are optimized for efficiency and consume fewer credits per request, while more powerful models like Claude 4.5 Sonnet consume more credits but offer enhanced capabilities.

## How are AI Credits Consumed?

AI credits are consumed on a per-request basis - every time you interact with an AI model, it counts as a request and consumes credits based on the model used.

There are four main ways your AI credits are consumed on MindPal:

1. **Direct Agent Interactions**: When you run an AI agent within MindPal, each query counts as a separate request
2. **Published Agent (Chatbot) Interactions**: When others use your published AI agents (chatbots), each query counts as a separate request
3. **Multi-Agent Workflow Runs**: When running workflows inside the app, each step counts as a separate request
4. **Published Workflow (Form) Runs**: When your published multi-agent workflows or forms are run from outside MindPal

## AI Credit Costs by Model

Here's a comprehensive reference of credit costs per request for each AI model:

### OpenAI Models

| Model | Credits per Request | Best For |
|-------|---------------------|----------|
| GPT-5.1 | 15 | Latest flagship model |
| GPT-5 | 15 | High-quality general tasks |
| GPT-5 Mini | 3 | Balanced quality and cost |
| GPT-5 Nano | 1 | Fast, simple tasks |
| GPT-4.1 | 15 | Complex reasoning |
| GPT-4.1 Mini | 3 | Cost-effective quality |
| o4 Mini | 8 | Reasoning tasks |
| o3 | 100 | Advanced reasoning |
| o3 Mini | 10 | Reasoning at lower cost |

### Anthropic (Claude) Models

| Model | Credits per Request | Best For |
|-------|---------------------|----------|
| Claude Opus 4.5 | 40 | Most capable, complex tasks |
| Claude 4.5 Sonnet | 20 | Excellent balance |
| Claude 4 Sonnet | 20 | High-quality writing |
| Claude 3.5 Sonnet | 20 | Reliable performance |
| Claude 4.5 Haiku | 10 | Fast responses |
| Claude 3 Haiku | 5 | Budget-friendly |

### Google (Gemini) Models

| Model | Credits per Request | Best For |
|-------|---------------------|----------|
| Gemini 3.0 Pro | 10 | Latest Pro capabilities |
| Gemini 3.0 Flash | 1 | Fast and efficient |
| Gemini 2.5 Pro | 10 | Strong reasoning |
| Gemini 2.5 Flash | 1 | Best value option |
| Gemini 2.5 Flash Lite | 1 | Lightweight tasks |

### DeepSeek Models

| Model | Credits per Request | Best For |
|-------|---------------------|----------|
| DeepSeek V3 | 0.5 | Cost-effective coding |
| DeepSeek R1 | 0.5 | Reasoning tasks |

### Perplexity Models

| Model | Credits per Request | Best For |
|-------|---------------------|----------|
| Sonar | 1 | Quick web search |
| Sonar Pro | 10 | Enhanced search |
| Sonar Reasoning | 10 | Search with reasoning |
| Sonar Deep Research | 20 | In-depth research |

### XAI (Grok) Models

| Model | Credits per Request | Best For |
|-------|---------------------|----------|
| Grok 2 Latest | 10 | General tasks |
| Grok 2 Vision | 10 | Image understanding |
| Grok 4 Fast | 1 | Quick responses |

### Other Models

| Model | Credits per Request | Provider |
|-------|---------------------|----------|
| LLaMa 3.3 70b | 3 | Groq |
| LLaMa 3.1 70b | 1 | Groq |
| LLaMa 3.1 8b | 1 | Groq |
| Kimi K2 | 1 | Groq |

### Speech Models (Text-to-Speech)

| Model | Credits per Minute | Notes |
|-------|-------------------|-------|
| Gemini 2.5 Pro TTS | 120 | High quality |
| Gemini 2.5 Flash TTS | 60 | Balanced |
| GPT-4o Mini TTS | 80 | OpenAI voice |

### Video Generation Models

| Model | Credits per Second | Default Video |
|-------|-------------------|---------------|
| Veo 3.1 Fast | 20 | ~160 credits (8s) |
| Veo 3.1 Standard | 50 | ~400 credits (8s) |
| Veo 3.0 Fast | 20 | ~160 credits (8s) |
| Veo 3.0 Standard | 50 | ~400 credits (8s) |

import { Callout } from "nextra/components";

<Callout emoji="ðŸ’¡">
  **Cost Optimization Tip**: For most tasks, start with cost-effective models like Gemini 2.5 Flash (1 credit) or GPT-5 Mini (3 credits). Upgrade to premium models only when you need higher quality output.
</Callout>

## Checking Model-Specific Credit Consumption

To view the exact credit consumption for each model:

1. Open any agent in your workspace
2. Navigate to the language model settings
3. Look for the information next to each model name

![Language model selector showing different models and their credit costs](/features/agent/language-model/language-model-selector.png)

## Managing Credit Consumption in Workflows

### Credit Estimation

Before running a workflow, you can estimate its credit cost:

1. Start building any workflow (you can do this with a free account)
2. Look at the top left corner of your workflow builder
3. You'll see a real-time estimation of the total AI credits required

Remember that these are estimates, and actual consumption may vary based on the actual steps taking place at that time.

![Helper tooltips showing credit consumption details](/features/workflow/builder/helpers.png)

### Viewing Actual Consumption

To see the exact number of AI credits consumed by a workflow:

1. Open any completed workflow run from your history
2. The exact AI credit cost for that specific run will be displayed

![Example of AI credit consumption in a workflow run](/features/workflow/runner/ai-credit-consumption.png)

This helps you track actual usage and validate your estimations.
